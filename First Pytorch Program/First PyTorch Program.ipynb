{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6cd2d3c",
   "metadata": {},
   "source": [
    " # First PyTorch Program\n",
    " \n",
    " The following rudimentary model code is implemented from the PyTorch beginner's tutorial page: [PyTorch Quickstart Tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html). The model is built to make predictions on the FashionMNIST dataset.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1e15aa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a4d99",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc356164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Train data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root = 'Data',\n",
    "    train = True,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")\n",
    "\n",
    "#### Test data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root = 'Data',\n",
    "    train = False,\n",
    "    download = True,\n",
    "    transform = ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bf08da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of train dataset :  60000\n",
      "Length of test dataset :  10000\n"
     ]
    }
   ],
   "source": [
    "print('Length of train dataset : ', len(train_data))\n",
    "print('Length of test dataset : ', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927424d",
   "metadata": {},
   "source": [
    "## Wrapping dataset with a DataLoader()\n",
    "\n",
    "Data Loader allows the dataset to be interable. The DataLoader allows batching, sampling, shuffling and multi-process data loading. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6928a65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W] =  torch.Size([64, 1, 28, 28])\n",
      "Shape of y =  torch.Size([64])\n",
      "Dtype of y =  torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print('Shape of X [N, C, H, W] = ', X.shape)\n",
    "    print('Shape of y = ', y.shape)\n",
    "    print('Dtype of y = ', y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9263ca",
   "metadata": {},
   "source": [
    "The size of one batch of the test DataLoader is printed above. In the dimensions of **X**:\n",
    "\n",
    "- **N** represents the number of data points in the batch, which is specified as 64.\n",
    "- **C** is the number of channels. For the FashionMNIST dataset, images have only one color channel.\n",
    "- **H** and **W** are the height and width of the images, respectively, both of which are 28.\n",
    "\n",
    "The target variable **y** is an integer indicating which class the image belongs to. There are a total of 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e66f243",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "\n",
    "To define the architecture of the model we are building, we create a class that specifies all the layers of the neural network and how data passes through them. This class inherits from `nn.Module`. The architecture is defined in the `__init__` function, and the data passing logic is implemented in the `forward` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbedb9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        out = self.network(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc14713b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (network): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06addb84",
   "metadata": {},
   "source": [
    "## Training the model and Optimizing the model parameters\n",
    "\n",
    "For training the model and optimizing the parameters, we need to define a loss function and the optimization method. For the current code, we are using the cross entropy loss, and Stochastic Gradient descent optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f40d1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3) # The learning rate is set as 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59928e67",
   "metadata": {},
   "source": [
    "The cross-entropy loss $ L $ is defined as:\n",
    "\n",
    "$$ L = -\\sum_{i=1}^{N} \\sum_{c=1}^{C} y_{i,c} \\log(\\hat{y}_{i,c}) $$\n",
    "\n",
    "where:\n",
    "- $ N $ is the number of samples \n",
    "- $ C $ is the number of classes\n",
    "- $ y_{i,c} $ is the binary indicator (0 or 1) if class label $ c $ is the correct classification for sample $ i $\n",
    "- $ \\hat{y}_{i,c} $ is the predicted probability that sample $ i $ belongs to class $ c $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0635fb",
   "metadata": {},
   "source": [
    "The update rule for stochastic gradient descent is:\n",
    "\n",
    "$$ \\theta = \\theta - \\eta \\nabla_{\\theta} J(\\theta; x^{(i)}; y^{(i)}) $$\n",
    "\n",
    "where:\n",
    "- $ \\theta $ is the parameter vector.\n",
    "- $\\eta $ is the learning rate.\n",
    "- $ \\nabla_{\\theta} J(\\theta; x^{(i)}; y^{(i)}) $ is the gradient of the cost function $ J $ with respect to the parameters $ \\theta $ for the i-th training example $ (x^{(i)}, y^{(i)}) $.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6524f87",
   "metadata": {},
   "source": [
    "### Training Function\n",
    "\n",
    "The training function computes the error in prediction and uses back propagation to adjust the model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5bb02617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)     # Size of the training set\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        #### Back Propagation\n",
    "        loss.backward()                 # Compute the derivatives\n",
    "        optimizer.step()                # Updating the model parameters\n",
    "        optimizer.zero_grad()           # Setting the grad values to zero after one step of updating parameters\n",
    "        \n",
    "        #### Print the training progress\n",
    "        if batch%100 == 0:\n",
    "            current = (batch+1)*len(X)    # No. of data points the model has been trained on\n",
    "            loss = loss.item()          # Get the loss value of the current training sample\n",
    "            print(f\"Loss : {loss:>7f} [{current:>5d} / {size:>5d}]\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2e128e",
   "metadata": {},
   "source": [
    "### Test Function\n",
    "\n",
    "The test function is to check the performance of the adjusted model parameters on the test set. The errors from the test set are not used in the parameter optimization to avoid over fitting and generalize the model to unseen data points. The train and test loss are monitored to ensure that the model is learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f544db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    batches = len(dataloader)\n",
    "    \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for (X,y) in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(axis = 1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "        test_loss = test_loss/batches\n",
    "        correct = correct/ size\n",
    "        \n",
    "    print(f\"Test Error: Average Loss = {test_loss:>8f}, Accuracy = {correct*100 :>0.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dc6ce8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 \n",
      "______________________________\n",
      "Loss : 1.671026 [   64 / 60000]\n",
      "Loss : 1.637307 [ 6464 / 60000]\n",
      "Loss : 1.481301 [12864 / 60000]\n",
      "Loss : 1.558274 [19264 / 60000]\n",
      "Loss : 1.439580 [25664 / 60000]\n",
      "Loss : 1.419454 [32064 / 60000]\n",
      "Loss : 1.440982 [38464 / 60000]\n",
      "Loss : 1.350231 [44864 / 60000]\n",
      "Loss : 1.390479 [51264 / 60000]\n",
      "Loss : 1.279226 [57664 / 60000]\n",
      "Test Error: Average Loss = 1.310160, Accuracy = 63.6%\n",
      "Epoch 2 \n",
      "______________________________\n",
      "Loss : 1.386322 [   64 / 60000]\n",
      "Loss : 1.363456 [ 6464 / 60000]\n",
      "Loss : 1.192834 [12864 / 60000]\n",
      "Loss : 1.302594 [19264 / 60000]\n",
      "Loss : 1.177310 [25664 / 60000]\n",
      "Loss : 1.193406 [32064 / 60000]\n",
      "Loss : 1.213665 [38464 / 60000]\n",
      "Loss : 1.144922 [44864 / 60000]\n",
      "Loss : 1.188989 [51264 / 60000]\n",
      "Loss : 1.089250 [57664 / 60000]\n",
      "Test Error: Average Loss = 1.120105, Accuracy = 65.0%\n",
      "Epoch 3 \n",
      "______________________________\n",
      "Loss : 1.190905 [   64 / 60000]\n",
      "Loss : 1.189152 [ 6464 / 60000]\n",
      "Loss : 1.004328 [12864 / 60000]\n",
      "Loss : 1.145257 [19264 / 60000]\n",
      "Loss : 1.017296 [25664 / 60000]\n",
      "Loss : 1.043827 [32064 / 60000]\n",
      "Loss : 1.077629 [38464 / 60000]\n",
      "Loss : 1.016573 [44864 / 60000]\n",
      "Loss : 1.062213 [51264 / 60000]\n",
      "Loss : 0.974287 [57664 / 60000]\n",
      "Test Error: Average Loss = 1.000377, Accuracy = 66.1%\n",
      "Epoch 4 \n",
      "______________________________\n",
      "Loss : 1.057873 [   64 / 60000]\n",
      "Loss : 1.078097 [ 6464 / 60000]\n",
      "Loss : 0.877324 [12864 / 60000]\n",
      "Loss : 1.042970 [19264 / 60000]\n",
      "Loss : 0.920402 [25664 / 60000]\n",
      "Loss : 0.940091 [32064 / 60000]\n",
      "Loss : 0.992283 [38464 / 60000]\n",
      "Loss : 0.933440 [44864 / 60000]\n",
      "Loss : 0.977066 [51264 / 60000]\n",
      "Loss : 0.900400 [57664 / 60000]\n",
      "Test Error: Average Loss = 0.920949, Accuracy = 67.5%\n",
      "Epoch 5 \n",
      "______________________________\n",
      "Loss : 0.962146 [   64 / 60000]\n",
      "Loss : 1.003080 [ 6464 / 60000]\n",
      "Loss : 0.788462 [12864 / 60000]\n",
      "Loss : 0.972426 [19264 / 60000]\n",
      "Loss : 0.857743 [25664 / 60000]\n",
      "Loss : 0.864725 [32064 / 60000]\n",
      "Loss : 0.934167 [38464 / 60000]\n",
      "Loss : 0.878016 [44864 / 60000]\n",
      "Loss : 0.916667 [51264 / 60000]\n",
      "Loss : 0.848573 [57664 / 60000]\n",
      "Test Error: Average Loss = 0.864740, Accuracy = 68.8%\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "#### Implement model training\n",
    "\n",
    "epochs = 5\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f\"\\nEpoch {t+1} \\n______________________________\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "\n",
    "print('Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376c4ee7",
   "metadata": {},
   "source": [
    "## Making Predictions with the model\n",
    "\n",
    "Now that the model is trained and ready to be used, we can try some sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45a9a07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b5674e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Coat, Actual: Coat\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "i = 888     #Give values from 0 to 9999 to test the model predictions\n",
    "x,y = test_data[i][0], test_data[i][1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax()], classes[y]\n",
    "    \n",
    "plt.imshow(x.permute(1, 2, 0))\n",
    "print(f\"Predicted: {predicted}, Actual: {actual}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
